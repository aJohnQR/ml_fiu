{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.special import entr\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed functions for processing the data.\n",
    "\n",
    "# Function to clean text data.\n",
    "def clean_review(text):\n",
    "    # Strip HTML tags\n",
    "    text = re.sub('<[^<]+?>', ' ', text)\n",
    " \n",
    "    # Strip escaped quotes\n",
    "    text = text.replace('\\\\\"', '')\n",
    " \n",
    "    # Strip quotes\n",
    "    text = text.replace('\"', '')\n",
    "    \n",
    "    # Strip @\n",
    "    text = text.replace('@', '')\n",
    " \n",
    "    return text\n",
    "\n",
    "# Puts words into a onehot embedding for the ML models ... I think.\n",
    "def to_sequence(tokenizer, preprocessor, index, text):\n",
    "    words = tokenizer(preprocessor(text))\n",
    "    indexes = [index[word] for word in words if word in index]\n",
    "    return indexes\n",
    "\n",
    "# Shuffle the data function.\n",
    "def shuffle(X, y):\n",
    "    perm = np.random.permutation(len(X))\n",
    "    X = X[perm]\n",
    "    y = y[perm]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing for allImdb dataset.\n",
    "# allImdb Cell 1/4\n",
    "\n",
    "data_allImdb = []\n",
    "reader_allImdb = csv.reader(open('allImdb.csv'), delimiter=',')\n",
    "for row in reader_allImdb:\n",
    "    data_allImdb.extend(row)\n",
    "\n",
    "# Create empty lists to hold the sentences and sentiment data.\n",
    "# These lists contain all the data. The data will still need to get shuffled and split\n",
    "# into traing and test.\n",
    "data_sentiment_allImdb = []\n",
    "data_sentence_allImdb = []\n",
    "for i in range(2, len(data_allImdb)):   # Start at index so dont record column labels.\n",
    "    if (i % 2) == 0:\n",
    "        data_sentiment_allImdb.extend(data_allImdb[i])\n",
    "    else:\n",
    "        data_sentence_allImdb.extend([data_allImdb[i]])\n",
    "\n",
    "# Clean the sentence data i.e. removing html tags, ... etc.\n",
    "for row in range(0, len(data_sentence_allImdb)):\n",
    "    data_sentence_allImdb[row] = clean_review(data_sentence_allImdb[row])\n",
    "  \n",
    "# This next part has to be once for all the data ... Only execute the next few lines once!\n",
    "vectorizer = CountVectorizer(binary=True, stop_words=stopwords.words('english'), \n",
    "                             lowercase=True, min_df=3, max_df=0.9, max_features=5000)\n",
    "\n",
    "data_sentence_onehot_allImdb = vectorizer.fit_transform(data_sentence_allImdb)\n",
    "\n",
    "word2idx = {word: idx for idx, word in enumerate(vectorizer.get_feature_names())}\n",
    "tokenize = vectorizer.build_tokenizer()\n",
    "preprocess = vectorizer.build_preprocessor()\n",
    "N_FEATURES = len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
